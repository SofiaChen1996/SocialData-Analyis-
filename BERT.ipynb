{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (4.38.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: requests in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: transformers[torch] in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (4.38.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.22.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (2022.3.15)\n",
      "Requirement already satisfied: filelock in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (3.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.15.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (4.64.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (21.3)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.27.2)\n",
      "Requirement already satisfied: torch in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.2.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from accelerate>=0.21.0->transformers[torch]) (5.8.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers[torch]) (3.0.4)\n",
      "Requirement already satisfied: networkx in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from torch->transformers[torch]) (2.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from torch->transformers[torch]) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from torch->transformers[torch]) (2.11.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from jinja2->torch->transformers[torch]) (2.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from sympy->torch->transformers[torch]) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "#install the necessary library \n",
    "!pip install transformers\n",
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.22.4)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Requirement already satisfied: torch in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Requirement already satisfied: transformers[torch] in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (4.38.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (4.64.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.22.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (2022.3.15)\n",
      "Requirement already satisfied: requests in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.27.1)\n",
      "Requirement already satisfied: torch in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.2.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.27.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from accelerate>=0.21.0->transformers[torch]) (5.8.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers[torch]) (3.0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from torch->transformers[torch]) (2.11.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from torch->transformers[torch]) (2.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from torch->transformers[torch]) (1.10.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from jinja2->torch->transformers[torch]) (2.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sofia_chen\\anaconda3\\lib\\site-packages (from sympy->torch->transformers[torch]) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n",
    "!pip install torch\n",
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the training set and the test set \n",
    "train_df = pd.read_csv('C://Users//Sofia_Chen//Desktop//ds//train_b.csv',encoding='ISO-8859-1')\n",
    "test_df = pd.read_csv('C://Users//Sofia_Chen//Desktop//ds//test_b.csv',encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2828.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.52546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.49944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label\n",
       "count  2828.00000\n",
       "mean      0.52546\n",
       "std       0.49944\n",
       "min       0.00000\n",
       "25%       0.00000\n",
       "50%       1.00000\n",
       "75%       1.00000\n",
       "max       1.00000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n",
    "#remove the not necessry column \n",
    "#column_dr=['Unnamed: 2', 'Unnamed: 3']\n",
    "#train_df=train_df.drop(column_dr, axis=1)\n",
    "train_df.head()\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check the missing value \n",
    "missing_train = train_df.isnull().sum()\n",
    "print(missing_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>715.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.516084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label\n",
       "count  715.000000\n",
       "mean     0.516084\n",
       "std      0.500091\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      1.000000\n",
       "75%      1.000000\n",
       "max      1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()\n",
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check the missing value \n",
    "missing_test = test_df.isnull().sum()\n",
    "print(missing_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label columns to integers\n",
    "train_df['label'] = train_df['label'].astype(int)\n",
    "test_df['label'] = test_df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class StressDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the datasets\n",
    "train_data = StressDataset(train_df['text'].tolist(), train_df['label'].tolist(), tokenizer)\n",
    "test_data = StressDataset(test_df['text'].tolist(), test_df['label'].tolist(), tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(train_df['label'].unique()))\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8080d0cc504e238b801709d6ad809f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1062 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acac247a40ad435288f09f8f54c51a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42403385043144226, 'eval_runtime': 255.1531, 'eval_samples_per_second': 2.802, 'eval_steps_per_second': 0.353, 'epoch': 1.0}\n",
      "{'loss': 0.5189, 'grad_norm': 1.9521071910858154, 'learning_rate': 5e-05, 'epoch': 1.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results\\checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1816c398f4f54e7d961b714717f7ddc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5790799856185913, 'eval_runtime': 244.7531, 'eval_samples_per_second': 2.921, 'eval_steps_per_second': 0.368, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results\\checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2858, 'grad_norm': 0.06355748325586319, 'learning_rate': 5.516014234875446e-06, 'epoch': 2.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846f88e6ce784305b1278f87d6d6d4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9637812972068787, 'eval_runtime': 241.0469, 'eval_samples_per_second': 2.966, 'eval_steps_per_second': 0.373, 'epoch': 3.0}\n",
      "{'train_runtime': 10470.1529, 'train_samples_per_second': 0.81, 'train_steps_per_second': 0.101, 'train_loss': 0.3869064208926903, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1062, training_loss=0.3869064208926903, metrics={'train_runtime': 10470.1529, 'train_samples_per_second': 0.81, 'train_steps_per_second': 0.101, 'train_loss': 0.3869064208926903, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da86557f00be4107a92835c33d211717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.9637812972068787, 'test_runtime': 249.099, 'test_samples_per_second': 2.87, 'test_steps_per_second': 0.361}\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_data)\n",
    "predicted_labels = predictions.predictions.argmax(-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5badc8a8452748f7a4bdfe5d934ecf57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7944055944055944\n",
      "Precision: 0.7642857142857142\n",
      "Recall: 0.8699186991869918\n",
      "F1 Score: 0.8136882129277566\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "predictions = trainer.predict(test_data)\n",
    "\n",
    "# Convert logits to predicted class (0 or 1) assuming binary classification\n",
    "pred_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# True labels\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='binary')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.9637812972068787, 'test_runtime': 249.099, 'test_samples_per_second': 2.87, 'test_steps_per_second': 0.361}\n"
     ]
    }
   ],
   "source": [
    "# If you have defined compute_metrics\n",
    "print(predictions.metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
